{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "id_path = \"registry_ids.csv\"\n",
    "loc_ids = pd.read_csv(id_path).values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_and_process_file(file_path):\n",
    "    result_list = []\n",
    "\n",
    "    try:\n",
    "        with open(file_path, 'r') as file:\n",
    "            lines = file.readlines()\n",
    "\n",
    "            # Extract every second line\n",
    "            for i in range(1, len(lines), 2):\n",
    "                line = lines[i].strip()\n",
    "\n",
    "                # Split the line into a list of integers\n",
    "                integer_series = list(map(int, line.split()))\n",
    "\n",
    "                result_list.append(integer_series)\n",
    "\n",
    "        return result_list\n",
    "\n",
    "    except FileNotFoundError:\n",
    "        print(\"File not found. Please check the file path.\")\n",
    "        return None\n",
    "    except Exception as e:\n",
    "        print(\"An error occurred:\", e)\n",
    "        return None\n",
    "\n",
    "def create_csv_from_2d_list(values, loc_ids, file_name=\"brownfields_top20_output.csv\"):\n",
    "    # Sum each column of the 2D list\n",
    "    column_sums = [sum(col) for col in zip(*values)]\n",
    "    # Create a DataFrame with indices and summed column values\n",
    "    df = pd.DataFrame({\n",
    "        'loc_ids': loc_ids,\n",
    "        'obs_values': column_sums})\n",
    "    df_sorted = df.sort_values(by=df.columns[1], ascending=False)\n",
    "    # Save the DataFrame to a CSV file in the same directory\n",
    "    df_sorted.to_csv(file_name, index=False)\n",
    "\n",
    "def normalize_history(history):\n",
    "    for line in history:\n",
    "        sum=0\n",
    "        for element in line:\n",
    "            sum=sum+element[1]\n",
    "        for element in line:\n",
    "            element[1]=element[1]/sum\n",
    "\n",
    "def get_history_indices_list(history):\n",
    "    index_list=[]\n",
    "    for line in history:\n",
    "        for element in line:\n",
    "            if element[0] not in index_list:\n",
    "                index_list.append(element[0])\n",
    "    return index_list\n",
    "\n",
    "def normalize_read_list(list):\n",
    "    line_counter=0\n",
    "    for line in list:\n",
    "        sum=0\n",
    "        for element in line:\n",
    "            sum=sum+element\n",
    "        element_counter=0\n",
    "        for element in line:\n",
    "            list[line_counter][element_counter]=element/sum\n",
    "            element_counter+=1\n",
    "        line_counter+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "master_distrib=[0]*16057 # num locs + 1, CAREFUL, this list starts from index 1 TO PLOT the right location indices. The exported location indices also start from 1. \n",
    "# The data for brownfield indices start from 0. After exporting the best indices, subtract 1 from them while accessing to brownfield data. \n",
    "master_top_10=[[0,0] for i in range(22)]\n",
    "file_name=\"recorder.txt\"\n",
    "read_list=read_and_process_file(file_name)\n",
    "history=[]\n",
    "\n",
    "# Get the resulting list, normalize it inside each combination length, sum them for each location and get the indices of top n observation rates.\n",
    "normalize_read_list(read_list)\n",
    "np_read_list=np.array(read_list)\n",
    "column_sums = np.sum(np_read_list, axis=0)\n",
    "indexed_column_sums=[]\n",
    "for i in range(len(column_sums)):\n",
    "    indexed_column_sums.append([column_sums[i],i])\n",
    "np_indexed_column_sums=np.array(indexed_column_sums)\n",
    "sorted_column_sums = np_indexed_column_sums[np_indexed_column_sums[:, 0].argsort()[::-1]]\n",
    "\n",
    "trimmed_sums = sorted_column_sums[:20] \n",
    "\n",
    "# Get the results of top 20 observed locations\n",
    "index_list=[x[1] for x in trimmed_sums]\n",
    "index_list=sorted(index_list)\n",
    "index_list=[int(x) for x in index_list]\n",
    "included_history=[]\n",
    "for line in read_list:\n",
    "    included_line=[]\n",
    "    for i in range(len(line)):\n",
    "        if i in index_list:\n",
    "            included_line.append(line[i])\n",
    "    included_history.append(included_line)\n",
    "\n",
    "np_amplitudes=np.array(included_history)\n",
    "\n",
    "id_prints=[]\n",
    "for index in index_list:\n",
    "    id_prints.append(loc_ids[index])\n",
    "\n",
    "create_csv_from_2d_list(included_history,id_prints,file_name=\"loc_id_vs_obs_rate.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_ids = pd.read_csv(\"loc_id_vs_obs_rate.csv\").values[:,0]\n",
    "\n",
    "row_sums = np.sum(np_amplitudes, axis=1)\n",
    "# Get indices to sort in descending order\n",
    "sorted_indices = np.argsort(row_sums)[::-1]\n",
    "# Sort the array\n",
    "sorted_np_amplitudes = np_amplitudes[sorted_indices]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
